{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import utils as u\n",
    "from models import Generator, Discriminator\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "from torch.utils.tensorboard.writer import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VARIÁVEIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOISE_DIM=100, N_CAMADAS=1, IMG_SIZE=8\n",
      "CPU times: user 134 µs, sys: 3.41 ms, total: 3.54 ms\n",
      "Wall time: 5.67 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "NOISE_DIM = 100\n",
    "N_CAMADAS = 1  # ASSIM, O TAMANHO DA IMAGEM SERÁ N_CAMADAS*8. [1->8x8, 2->16x16, 3->32x32, 4->64x64, 5->128x128, 6->256x256]\n",
    "IMG_SIZE = 4 * (2**N_CAMADAS)\n",
    "IMG_CHANNELS = 3\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 128\n",
    "MODELS_DIR = './models'\n",
    "IMGS_DIR = './imgs/celeba'\n",
    "TAXA_TREINAMENTO_DISCRIMINATOR = 5  # ou seja, o discriminator treina 5 vezes mais que o generator\n",
    "LAMBDA_GP = 10 # TAXA DO GRADIENT PENALTY\n",
    "\n",
    "def criar_transformer(img_size_):\n",
    "    return  transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((img_size_, img_size_)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.Normalize(mean=(.5, .5, .5), std=(.5, .5, .5))\n",
    "    ])\n",
    "transformer = criar_transformer(img_size_=4)\n",
    "\n",
    "inv_transformer = transforms.Compose([\n",
    "    transforms.Normalize(mean=(-1., -1., -1.), std=(1., 1., 1.)),\n",
    "    transforms.ToPILImage(),\n",
    "])\n",
    "\n",
    "print (f'{NOISE_DIM=}, {N_CAMADAS=}, {IMG_SIZE=}')\n",
    "\n",
    "writer = SummaryWriter('./logs/pg-wgan-celeba')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspeção de algumas imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dataset)=202599\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.27 s, sys: 89.5 ms, total: 1.36 s\n",
      "Wall time: 1.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = u.Custom_Dataset(IMGS_DIR, '*.jpg', transformer, inv_transformer)\n",
    "print (f'{len(dataset)=}')\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "grid_np = dataset.criar_grid_imagens_aleatorias(n_images=8, tipo='np')\n",
    "plt.figure(figsize=(20, 2))\n",
    "plt.imshow(grid_np)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos discriminator e generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator(img_channels=IMG_CHANNELS, n_camadas=N_CAMADAS, cfl=128)\n",
    "generator = Generator(img_channels=IMG_CHANNELS, noise_dim=NOISE_DIM, n_camadas=N_CAMADAS, cfl=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise.shape=torch.Size([3, 100, 1, 1])\n",
      "output_generator.shape=torch.Size([3, 3, 8, 8])\n",
      "output_discriminator.shape=torch.Size([3, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Testando os modelos\n",
    "noise = u.get_noise(3, NOISE_DIM)\n",
    "output_generator = generator(noise)\n",
    "output_discriminator = discriminator(output_generator)\n",
    "print (f'{noise.shape=}')\n",
    "print (f'{output_generator.shape=}')\n",
    "print (f'{output_discriminator.shape=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções úteis para o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(model_d, real_imgs, fake_imgs, device_):\n",
    "\n",
    "    b_size, c, h, w = real_imgs.shape\n",
    "    alpha = torch.rand((b_size, 1, 1, 1)).repeat(1, c, h, w).to(device_)\n",
    "    # tenta criar um tensor (b,c,h,w) onde cada elemento b (de dim c,h,w) possui um número aleatório em todas as posições\n",
    "\n",
    "    interpolated_imgs = real_imgs * alpha + fake_imgs * (1-alpha)\n",
    "\n",
    "    # Cálculo score\n",
    "    mixed_score = model_d(interpolated_imgs)\n",
    "\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs = interpolated_imgs,\n",
    "        outputs = mixed_score,\n",
    "        grad_outputs = torch.ones_like(mixed_score),\n",
    "        create_graph = True,\n",
    "        retain_graph = True\n",
    "    )[0]\n",
    "    \n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    penalty = torch.mean((gradient_norm-1) ** 2)\n",
    "    \n",
    "    return penalty\n",
    "\n",
    "def imprimir_imagem_checkpoint():\n",
    "    random_noise = u.get_noise(8, NOISE_DIM, device)\n",
    "    random_img = generator(random_noise)\n",
    "    img_np = u.criar_grid(random_img, nrow=8, inv_transformer=inv_transformer, tipo='np')\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.imshow(img_np)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação para treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento com N_CAMADAS=1 e tamanho das imagens IMG_SIZE=8\n",
      "Transformers criados.\n",
      "device=device(type='cpu')\n",
      "len(dataset)=202599, BATCH_SIZE=128, len(dataloader)=1583\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "discriminator = Discriminator(img_channels=3, n_camadas=N_CAMADAS, cfl=128)\n",
    "generator = Generator(img_channels=3, noise_dim=NOISE_DIM, n_camadas=N_CAMADAS, cfl=512)\n",
    "noise = u.get_noise(1, NOISE_DIM)\n",
    "output_generator = generator(noise)\n",
    "IMG_SIZE = output_generator.shape[-1]\n",
    "\n",
    "print (f'Treinamento com {N_CAMADAS=} e tamanho das imagens {IMG_SIZE=}')\n",
    "transformer = criar_transformer(img_size_=IMG_SIZE)\n",
    "print (f'Transformers criados.')\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (f'{device=}')\n",
    "\n",
    "discriminator.to(device)\n",
    "generator.to(device)\n",
    "\n",
    "optim_generator = torch.optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(0., 0.9))\n",
    "optim_discriminator = torch.optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(0., 0.9))\n",
    "\n",
    "dataset = u.Custom_Dataset(IMGS_DIR, pattern='*.jpg', transformer=transformer, inv_transformer=inv_transformer)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print (f'{len(dataset)=}, {BATCH_SIZE=}, {len(dataloader)=}')\n",
    "\n",
    "print (f'ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.train()\n",
    "discriminator.train()\n",
    "\n",
    "for epoch in range(1_000):\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    imprimir_imagem_checkpoint()\n",
    "    \n",
    "    print (f'{epoch=}')\n",
    "\n",
    "    for real_imgs in tqdm(dataloader):\n",
    "        real_imgs = real_imgs.to(device)\n",
    "        b_size = len(real_imgs)\n",
    "\n",
    "        # Treinando o discriminator\n",
    "        for _ in TAXA_TREINAMENTO_DISCRIMINATOR:\n",
    "            noise = u.get_noise(b_size, NOISE_DIM, device)\n",
    "            fake_imgs = generator(noise)\n",
    "\n",
    "            output_real = discriminator(real_imgs)\n",
    "            output_fake = discriminator(fake_imgs)\n",
    "\n",
    "            # Cálculo do Gradient-penalty\n",
    "            gp = gradient_penalty(discriminator, real_imgs, fake_imgs, device)\n",
    "            loss_discriminator = -(torch.mean(output_real.view(-1)) - torch.mean(output_fake.view(-1))) + LAMBDA_GP*gp\n",
    "            discriminator.zero_grad()\n",
    "            loss_discriminator.backward(retain_graph=True)\n",
    "            optim_discriminator.step()\n",
    "        \n",
    "        # Treinando o generator\n",
    "        output_fake_for_generator = discriminator(fake_imgs)\n",
    "        loss_generator = -torch.mean(output_fake_for_generator.view(-1))\n",
    "        generator.zero_grad()\n",
    "        loss_generator.backward()\n",
    "        optim_generator.step()\n",
    "\n",
    "    # Levando as variáveis para o tensorboard\n",
    "    writer.add_scalar('loss_discriminator', loss_discriminator.item(), epoch)\n",
    "    writer.add_scalar('loss_generator', loss_generator.item(), epoch)\n",
    "    \n",
    "    if (epoch % 100 == 0):\n",
    "        discriminator.save()\n",
    "        generator.save()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aa39838d5afd7d94b7544cb5e5351cace91d1e0eb74b6451fdb6f11f3a068bed"
  },
  "kernelspec": {
   "display_name": "principal:Python",
   "language": "python",
   "name": "conda-env-principal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
