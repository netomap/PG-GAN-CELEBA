{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import utils as u\n",
    "from models import Generator, Discriminator\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "from torch.utils.tensorboard.writer import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VARIÁVEIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOISE_DIM=100, N_CAMADAS=1, IMG_SIZE=8\n",
      "CPU times: user 1.43 s, sys: 209 ms, total: 1.64 s\n",
      "Wall time: 3.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "NOISE_DIM = 100\n",
    "N_CAMADAS = 1  # ASSIM, O TAMANHO DA IMAGEM SERÁ N_CAMADAS*8. [1->8x8, 2->16x16, 3->32x32, 4->64x64, 5->128x128, 6->256x256]\n",
    "IMG_SIZE = 4 * (2**N_CAMADAS)\n",
    "IMG_CHANNELS = 3\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 128\n",
    "MODELS_DIR = './models'\n",
    "IMGS_DIR = './imgs/celeba'\n",
    "TAXA_TREINAMENTO_DISCRIMINATOR = 5  # ou seja, o discriminator treina 5 vezes mais que o generator\n",
    "LAMBDA_GP = 10 # TAXA DO GRADIENT PENALTY\n",
    "\n",
    "def criar_transformer(img_size_):\n",
    "    return  transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((img_size_, img_size_)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.Normalize(mean=(.5, .5, .5), std=(.5, .5, .5))\n",
    "    ])\n",
    "transformer = criar_transformer(img_size_=4)\n",
    "\n",
    "inv_transformer = transforms.Compose([\n",
    "    transforms.Normalize(mean=(-1., -1., -1.), std=(1., 1., 1.)),\n",
    "    transforms.ToPILImage(),\n",
    "])\n",
    "\n",
    "print (f'{NOISE_DIM=}, {N_CAMADAS=}, {IMG_SIZE=}')\n",
    "\n",
    "writer = SummaryWriter('./logs/pg-wgan-celeba')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspeção de algumas imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(dataset)=202599\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAAB7CAYAAAA8LsLzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAGH0lEQVR4nO3dS4iVdRjH8ec4zpgX1IhULLKMpLKoRDdToBEohIaNgUbqytRq04WgIhJKjYLauTAyiYoky0gypCgpNbQEL2QyZlhk4q3yUjpqelq0nllIPPHI57P9L37vHGZezvd9F9NoNpsBAABAPb3+7wsAAADgwgg6AACAogQdAABAUYIOAACgKEEHAABQlKADAAAoqndPh7u2bEj7nwbzZk7Pmop7OjrStibPfiRtKyLi5ptuTNuaOTvvc1z7ybq0rQMHj6Zttd8xKW0rIuK7HRvTtloaec+LXn/zo7StSRPHpG1dzJrNc2lbm77Znbb1+PSJaVvPv7Eibat3S/+0rYiIAXvy7vntd41N22r0aknbevbp5WlbL616N23rX+fTlibMWJy29dlbT6ZtnTmdNhV/rsv7uSIiDqzfl7a16OudaVvvbehsdHfmDR0AAEBRgg4AAKAoQQcAAFCUoAMAAChK0AEAABQl6AAAAIoSdAAAAEUJOgAAgKIEHQAAQFGCDgAAoChBBwAAUJSgAwAAKErQAQAAFCXoAAAAihJ0AAAARQk6AACAogQdAABAUYIOAACgKEEHAABQlKADAAAoStABAAAUJegAAACKEnQAAABFCToAAICiBB0AAEBRgg4AAKCo3j0dDvr7UNZ1xIcrV6Rtbf1qZdrWzs7v07YiIh6a/0Da1uDmb2lb024amra15ODxtK2f9+9N24qI+HLJi2lbx38/nLb1zqer07Ym3D4ibevwxtfStiIihrcNT9s6P/6+tK1XH+5I2zpxJO/+cdmh3Wlbp0aMTduKiBh9/RVpW61796Rt/bRqU9rW+Yv4kf3kGfPTtvZt35W2ddtdO9K2tqxZlra144O1aVsREXe//UPaVr+2trStnlzEf+4AAAAXN0EHAABQlKADAAAoStABAAAUJegAAACKEnQAAABFCToAAICiBB0AAEBRgg4AAKAoQQcAAFCUoAMAAChK0AEAABQl6AAAAIoSdAAAAEUJOgAAgKIEHQAAQFGCDgAAoChBBwAAUJSgAwAAKErQAQAAFCXoAAAAihJ0AAAARQk6AACAogQdAABAUYIOAACgKEEHAABQVO+eDo8cPJR1HdH4dUve1h9pU/HFxwvyxiKidfBVaVsT2u9I21q372Ta1pChB9K2nnvhpbStiIi2v39J2+rXp0/a1v3Tp6Zt7Vw6N23rhlFT0rYiIs605W316mpJ2xp++aC0rTcWvpK2dbTrWNrW5s5taVsREbffOjBt6+SR/WlbP5/+M22r0Zr3Gb684Km0rYiIjqF53wmGzbk3bevbc33Tts6dP5O2NX759rStiIhTd85L29q9fnPaVk+8oQMAAChK0AEAABQl6AAAAIoSdAAAAEUJOgAAgKIEHQAAQFGCDgAAoChBBwAAUJSgAwAAKErQAQAAFCXoAAAAihJ0AAAARQk6AACAogQdAABAUYIOAACgKEEHAABQlKADAAAoStABAAAUJegAAACKEnQAAABFCToAAICiBB0AAEBRgg4AAKAoQQcAAFCUoAMAAChK0AEAABQl6AAAAIpqNJvNbg+XzG3v/vA/ds3V12ZNRUvX6bStUePa07YiIsbNWZy2Nf66K9O2zja60rbWbNmbtjXs8uFpWxERQ/q3pG2d+OtY2ta0WY+mbU0ZujFta8AlY9K2IiIeW7AwbWvN1s60rZEjb0nbGj2wb9rWwcRHsgNbG3ljEbF6Wd7v4rYd+9O2Zr+4Im1rcGve/f6ZRU+kbUVEzJrzYNrW3KmT0rZ+7HV12tbn7y9N24rIvX+0NAambZ09m/edsdFyabcfpDd0AAAARQk6AACAogQdAABAUYIOAACgKEEHAABQlKADAAAoStABAAAUJegAAACKEnQAAABFCToAAICiBB0AAEBRgg4AAKAoQQcAAFCUoAMAAChK0AEAABQl6AAAAIoSdAAAAEUJOgAAgKIEHQAAQFGCDgAAoChBBwAAUJSgAwAAKErQAQAAFCXoAAAAihJ0AAAARQk6AACAohrNZvP/vgYAAAAugDd0AAAARQk6AACAogQdAABAUYIOAACgKEEHAABQlKADAAAo6h9tNMUV7tA62AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.16 s, sys: 90.2 ms, total: 1.25 s\n",
      "Wall time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataset = u.Custom_Dataset(IMGS_DIR, '*.jpg', transformer, inv_transformer)\n",
    "print (f'{len(dataset)=}')\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "grid_np = dataset.criar_grid_imagens_aleatorias(n_images=8, tipo='np')\n",
    "plt.figure(figsize=(20, 2))\n",
    "plt.imshow(grid_np)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos discriminator e generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator(img_channels=IMG_CHANNELS, n_camadas=N_CAMADAS, cfl=128)\n",
    "generator = Generator(img_channels=IMG_CHANNELS, noise_dim=NOISE_DIM, n_camadas=N_CAMADAS, cfl=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise.shape=torch.Size([3, 100, 1, 1])\n",
      "output_generator.shape=torch.Size([3, 3, 8, 8])\n",
      "output_discriminator.shape=torch.Size([3, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Testando os modelos\n",
    "noise = u.get_noise(3, NOISE_DIM)\n",
    "output_generator = generator(noise)\n",
    "output_discriminator = discriminator(output_generator)\n",
    "print (f'{noise.shape=}')\n",
    "print (f'{output_generator.shape=}')\n",
    "print (f'{output_discriminator.shape=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções úteis para o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(model_d, real_imgs, fake_imgs, device_):\n",
    "\n",
    "    b_size, c, h, w = real_imgs.shape\n",
    "    alpha = torch.rand((b_size, 1, 1, 1)).repeat(1, c, h, w).to(device_)\n",
    "    # tenta criar um tensor (b,c,h,w) onde cada elemento b (de dim c,h,w) possui um número aleatório em todas as posições\n",
    "\n",
    "    interpolated_imgs = real_imgs * alpha + fake_imgs * (1-alpha)\n",
    "\n",
    "    # Cálculo score\n",
    "    mixed_score = model_d(interpolated_imgs)\n",
    "\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs = interpolated_imgs,\n",
    "        outputs = mixed_score,\n",
    "        grad_outputs = torch.ones_like(mixed_score),\n",
    "        create_graph = True,\n",
    "        retain_graph = True\n",
    "    )[0]\n",
    "    \n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    penalty = torch.mean((gradient_norm-1) ** 2)\n",
    "    \n",
    "    return penalty\n",
    "\n",
    "def imprimir_imagem_checkpoint():\n",
    "    random_noise = u.get_noise(8, NOISE_DIM, device)\n",
    "    random_img = generator(random_noise)\n",
    "    img_np = u.criar_grid(random_img, nrow=8, inv_transformer=inv_transformer, tipo='np')\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    plt.imshow(img_np)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação para treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento com N_CAMADAS=1 e tamanho das imagens IMG_SIZE=8\n",
      "Transformers criados.\n",
      "device=device(type='cuda', index=0)\n",
      "len(dataset)=202599, BATCH_SIZE=128, len(dataloader)=1583\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "discriminator = Discriminator(img_channels=3, n_camadas=N_CAMADAS, cfl=128)\n",
    "generator = Generator(img_channels=3, noise_dim=NOISE_DIM, n_camadas=N_CAMADAS, cfl=512)\n",
    "noise = u.get_noise(1, NOISE_DIM)\n",
    "output_generator = generator(noise)\n",
    "IMG_SIZE = output_generator.shape[-1]\n",
    "\n",
    "print (f'Treinamento com {N_CAMADAS=} e tamanho das imagens {IMG_SIZE=}')\n",
    "transformer = criar_transformer(img_size_=IMG_SIZE)\n",
    "print (f'Transformers criados.')\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (f'{device=}')\n",
    "\n",
    "discriminator.to(device)\n",
    "generator.to(device)\n",
    "\n",
    "optim_generator = torch.optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(0., 0.9))\n",
    "optim_discriminator = torch.optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(0., 0.9))\n",
    "\n",
    "dataset = u.Custom_Dataset(IMGS_DIR, pattern='*.jpg', transformer=transformer, inv_transformer=inv_transformer)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print (f'{len(dataset)=}, {BATCH_SIZE=}, {len(dataloader)=}')\n",
    "\n",
    "print (f'ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.train()\n",
    "discriminator.train()\n",
    "\n",
    "for epoch in range(1_000):\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    imprimir_imagem_checkpoint()\n",
    "    \n",
    "    print (f'{epoch=}')\n",
    "\n",
    "    for real_imgs in tqdm(dataloader):\n",
    "        real_imgs = real_imgs.to(device)\n",
    "        b_size = len(real_imgs)\n",
    "\n",
    "        # Treinando o discriminator\n",
    "        for _ in range(TAXA_TREINAMENTO_DISCRIMINATOR):\n",
    "            noise = u.get_noise(b_size, NOISE_DIM, device)\n",
    "            fake_imgs = generator(noise)\n",
    "\n",
    "            output_real = discriminator(real_imgs)\n",
    "            output_fake = discriminator(fake_imgs)\n",
    "\n",
    "            # Cálculo do Gradient-penalty\n",
    "            gp = gradient_penalty(discriminator, real_imgs, fake_imgs, device)\n",
    "            loss_discriminator = -(torch.mean(output_real.view(-1)) - torch.mean(output_fake.view(-1))) + LAMBDA_GP*gp\n",
    "            discriminator.zero_grad()\n",
    "            loss_discriminator.backward(retain_graph=True)\n",
    "            optim_discriminator.step()\n",
    "        \n",
    "        # Treinando o generator\n",
    "        output_fake_for_generator = discriminator(fake_imgs)\n",
    "        loss_generator = -torch.mean(output_fake_for_generator.view(-1))\n",
    "        generator.zero_grad()\n",
    "        loss_generator.backward()\n",
    "        optim_generator.step()\n",
    "\n",
    "    # Levando as variáveis para o tensorboard\n",
    "    writer.add_scalar('loss_discriminator', loss_discriminator.item(), epoch)\n",
    "    writer.add_scalar('loss_generator', loss_generator.item(), epoch)\n",
    "    \n",
    "    if (epoch % 100 == 0):\n",
    "        discriminator.save()\n",
    "        generator.save()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aa39838d5afd7d94b7544cb5e5351cace91d1e0eb74b6451fdb6f11f3a068bed"
  },
  "kernelspec": {
   "display_name": "principal:Python",
   "language": "python",
   "name": "conda-env-principal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
